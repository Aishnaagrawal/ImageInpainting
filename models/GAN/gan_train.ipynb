{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "formal-entertainment",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pending-target",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Creating Generator\n",
    "train_datagen = ImageDataGenerator(validation_split = 0.2)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        \"/home/mihir_jain/data/\", target_size = (256, 256),color_mode = \"rgb\", batch_size=50,class_mode = \"input\",subset = \"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "consolidated-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    y_true_flattened = keras.backend.flatten(y_true)\n",
    "    y_pred_flattened = keras.backend.flatten(y_pred)\n",
    "    x = keras.backend.sum(y_true_flattened * y_pred_flattened)\n",
    "    y=keras.backend.sum(y_true_flattened + y_pred_flattened)\n",
    "    return 2*x/y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "indoor-defensive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class Generator():\n",
    "    def prepare_model(self, input_size=(256,256,3)):\n",
    "        acti_function = \"relu\"\n",
    "        padding = \"same\"\n",
    "        filters = 32\n",
    "        kernel_size = (3,3)\n",
    "        pool_size = (2,2)\n",
    "        up_kernel = (2,2)\n",
    "        up_stride = (2,2)\n",
    "\n",
    "        # Inputs\n",
    "        inputs = keras.layers.Input(input_size)\n",
    "\n",
    "        # encoder \n",
    "        conv1, pooling1 = self.Convulation_layer(filters,kernel_size, pool_size, acti_function, padding, inputs)\n",
    "        conv2, pooling2 = self.Convulation_layer(filters*2, kernel_size, pool_size, acti_function, padding, pooling1)\n",
    "        conv3, pooling3 = self.Convulation_layer(filters*4, kernel_size, pool_size, acti_function,padding, pooling2) \n",
    "        conv4, pooling4 = self.Convulation_layer(filters*8, kernel_size, pool_size, acti_function,padding, pooling3) \n",
    "        # decoder \n",
    "        conv5, up6 = self.Up_Convulation_layer(filters*16, filters*8, kernel_size, up_kernel, up_stride, acti_function, padding, pooling4, conv4)\n",
    "        conv6, up7 = self.Up_Convulation_layer(filters*8, filters*4, kernel_size, up_kernel, up_stride, acti_function,padding, up6, conv3)\n",
    "        conv7, up8 = self.Up_Convulation_layer(filters*4, filters*2, kernel_size, up_kernel, up_stride, acti_function, padding, up7, conv2)\n",
    "        conv8, up9 = self.Up_Convulation_layer(filters*2,filters, kernel_size, up_kernel, up_stride, acti_function,padding, up8, conv1)\n",
    "        conv9 = keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same')(up9)\n",
    "        conv9 = keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same')(conv9)\n",
    "        outputs = keras.layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(conv9)\n",
    "        return keras.models.Model(inputs=[inputs], outputs=[outputs]) \n",
    "    \n",
    "    def Convulation_layer(self, filters, kernel_size, pool_size, activation, padding, connecting_layer, pool_layer=True):\n",
    "        conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(connecting_layer)\n",
    "        conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(conv)\n",
    "        pooling = keras.layers.MaxPooling2D(pool_size)(conv)\n",
    "        return conv, pooling\n",
    "\n",
    "    def Up_Convulation_layer(self, filters, up_filters, kernel_size, up_kernel, up_stride, activation, padding, connecting_layer, shared_layer):\n",
    "        conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(connecting_layer)\n",
    "        conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(conv)\n",
    "        up = keras.layers.Conv2DTranspose(filters=up_filters, kernel_size=up_kernel, strides=up_stride, padding=padding)(conv)\n",
    "        up = keras.layers.concatenate([up, shared_layer], axis=3)\n",
    "        return conv, up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "senior-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(\"./logs_gan.txt\",\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "emerging-sleep",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def prepare_model(self, input_size = (256,256,3)):\n",
    "        activation = \"relu\"\n",
    "        padding = \"same\"\n",
    "        # input\n",
    "        inputs = keras.layers.Input(input_size)\n",
    "\n",
    "        # encoder\n",
    "        conv1 = keras.layers.Conv2D(filters = 64,kernel_size = (4,4),strides = 2, activation = activation,padding = padding)(inputs)\n",
    "        conv2 = keras.layers.Conv2D(filters = 128,kernel_size = (4,4),strides = 2, activation = activation,padding = padding)(conv1)\n",
    "        conv3 = keras.layers.Conv2D(filters = 256,kernel_size = (4,4),strides = 2, activation = activation,padding = padding)(conv2)\n",
    "        conv4 = keras.layers.Conv2D(filters = 512,kernel_size = (4,4),strides = 2, activation = activation,padding = padding)(conv3)\n",
    "\n",
    "        # Flatten\n",
    "        flat = keras.layers.Flatten()(conv4)\n",
    "\n",
    "        # Fully connected\n",
    "        output = keras.layers.Dense(units = 1, activation = \"sigmoid\")(flat)\n",
    "\n",
    "        return keras.models.Model(inputs=[inputs], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "familiar-commodity",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator().prepare_model()\n",
    "discriminator = Discriminator().prepare_model()\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "saving-shame",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "conventional-obligation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "latest-keeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss1(fake_output):\n",
    "    loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "    return loss\n",
    "\n",
    "def generator_loss2(real,output):\n",
    "    loss = tf.reduce_mean(tf.abs(tf.subtract(output, real)))\n",
    "    return loss\n",
    "\n",
    "def generator_loss(real, output, fake_output):\n",
    "    loss1 = generator_loss1(fake_output)\n",
    "    loss2 = generator_loss2(real, output)\n",
    "    tf.print(float(0.01*loss1 + 0.99*loss2))\n",
    "    return 0.01*loss1 + 0.99*loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dramatic-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x, y, generator, discriminator, opt1, opt2):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(x,training = True)\n",
    "        real_output = discriminator(y, training = True)\n",
    "        fake_output = discriminator(generated_images, training = True)\n",
    "        gen_loss = generator_loss(y,generated_images,fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "    tf.print(dice_coefficient(y,generated_images))\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    opt1.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    opt2.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "distant-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating masks for images\n",
    "def createmask(img,mask):\n",
    "    img = img.astype(np.uint8)\n",
    "    masked_image = np.copy(img)\n",
    "    for l in range(len(img)):\n",
    "        masked_image[l] = cv2.bitwise_and(img[l], mask)\n",
    "    return masked_image/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "billion-direction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch\n",
      "Epoch\n",
      "Epoch\n",
      "Epoch\n",
      "Epoch\n",
      "Epoch\n",
      "Epoch\n",
      "Epoch\n",
      "Epoch\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "mask = np.full((256,256,3), 255, np.uint8)\n",
    "\n",
    "orignal = sys.stdout\n",
    "\n",
    "# Creating a rectangular 64*64 mask\n",
    "for i in range(3):\n",
    "    for j in range(256):\n",
    "        for k in range(256):\n",
    "            if j>96 and 160>j and k>96 and 160>k:\n",
    "                mask[j][k][i] = 1\n",
    "epochs = 10\n",
    "cnt = 0\n",
    "num_images = 24000\n",
    "batch_size = 50\n",
    "batch_images = num_images//batch_size\n",
    "for epoch in range(1,epochs):\n",
    "    for x,y in train_generator:\n",
    "        x_mask = createmask(x,mask).astype(np.float32)\n",
    "        sys.stdout = fp\n",
    "        train_step(x_mask,y/255,generator, discriminator,generator_optimizer,discriminator_optimizer)\n",
    "        sys.stdout = orignal\n",
    "        cnt += 1\n",
    "        if (cnt == batch_images):\n",
    "            break\n",
    "        print(cnt,end = \"\\r\")\n",
    "    if epoch == 0:\n",
    "        for x,y in train_generator:\n",
    "            x_mask = createmask(x,mask).astype(np.float32)\n",
    "            yhat = generator.predict(x_mask)\n",
    "            y = y/255\n",
    "            plt.imshow(yhat[0])\n",
    "            break\n",
    "    cnt = 0\n",
    "    print(\"Epoch\")\n",
    "    generator.save_weights(\"./models_gan/d\"+str(epoch)+\".h5\")\n",
    "    discriminator.save_weights(\"./models_gan/g\"+str(epoch)+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-stewart",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
